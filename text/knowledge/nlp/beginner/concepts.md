# NLP 初级核心知识点（concepts.md）

本文件总结自然语言处理（NLP）初学者必须掌握的理论基础、核心技能和主流实践流程。学完这些知识，能理解NLP的基础任务、工具和实现方法，并独立完成最基础的NLP小项目。

---

## 1. NLP是什么？典型应用有哪些？

- **定义**：自然语言处理（NLP, Natural Language Processing）指让计算机能够理解、分析、处理和生成自然语言（文本或语音）的各类技术和方法。
- **常见应用**：文本分类、情感分析、关键词提取、文本聚类、机器翻译、对话机器人、垃圾邮件过滤、舆情监测等。

---

## 2. 文本数据基础处理

- **文本读取与编码处理**：学会用Python读取txt、csv、json等格式的文本数据，理解字符编码（如UTF-8）。
- **文本清洗**：包括去除标点、数字、特殊符号、统一大小写、去除多余空格等。

---

## 3. 分词与Tokenization

- **英文分词**：可直接按空格和标点分割。
- **中文分词**：需借助专用工具，如jieba库，实现“机械分词”。
- **分词结果**：将文本切割为一个个单词/词语，便于后续特征工程。

---

## 4. 停用词处理

- **停用词定义**：在文本中出现频率极高但意义不大的词（如“的”、“了”、“is”、“and”）。
- **停用词过滤**：加载常用停用词表，过滤无用词以提升特征有效性。
- 常见库如NLTK、jieba、scikit-learn自带停用词表。

---

## 5. 词频统计与可视化

- **词频统计**：统计每个词在文本中出现的次数，找出高频词、关键词。
- **可视化**：常用wordcloud库制作词云，也可用matplotlib、pandas等可视化统计结果。
- 可用于初步文本分析和特征提取。

---

## 6. 关键词提取

- **TF-IDF**（Term Frequency-Inverse Document Frequency）：衡量词对文本的重要性。高TF-IDF的词往往是文档的核心内容。
- 常用工具：scikit-learn的TfidfVectorizer、jieba.analyse等。

---

## 7. 简单文本特征工程

- **词袋模型（Bag of Words, BoW）**：将文本表示为“词-频率”的向量，是机器学习模型的输入基础。
- **CountVectorizer/TfidfVectorizer**：主流文本特征提取API。

---

## 8. 入门级文本建模与分类

- **常见算法**：朴素贝叶斯（Naive Bayes）最常见，适合小数据场景和文本分类入门。
- **实验流程**：
    1. 文本预处理 → 分词 → 去停用词 → 特征提取（如TF-IDF）
    2. 训练朴素贝叶斯模型（如sklearn）
    3. 对新文本做情感/类别预测
- **案例**：垃圾短信二分类、商品评论正负极性分析。

---

## 9. 主流NLP基础工具/库

- **jieba**：中文分词
- **NLTK**：英文文本处理
- **scikit-learn**：特征提取、机器学习分类
- **wordcloud**：词云图可视化
- **pandas**：数据加载和处理

---

## 10. NLP处理主流程（pipeline）

1. **文本获取**：读取本地文件/网络文本
2. **文本清洗**：去标点、大小写归一化等
3. **分词**：按语言特性拆分单词/词语
4. **去除停用词**：过滤无效高频词
5. **特征提取**：如TF-IDF/BoW向量化
6. **建模与分类**：如朴素贝叶斯实现情感/垃圾短信/主题分类
7. **结果可视化/分析**：如输出高频词、生成词云

---

## 11. 初级NLP能力要求

- 会用Python基础和主流NLP工具做文本预处理与特征提取
- 能完成分词、词频统计、简单分类、关键词提取等典型任务
- 能独立查找和使用官方文档解决常见报错
- 理解NLP pipeline整体思路

---

## 🔗 进阶建议

- 完成上述基础知识点后，推荐尝试更复杂的数据集和特征工程、进阶机器学习/深度学习模型，逐步挑战 intermediate 难度。

---

> 建议边学边实践，相关案例和代码详见 [mini_cases/](./mini_cases/) 目录。

